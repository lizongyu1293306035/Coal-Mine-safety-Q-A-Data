{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f0d4ec-96ff-409e-aae1-566856196df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 09-13 15:45:14 [__init__.py:241] Automatically detected platform cuda.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.8.9: Fast Qwen2 patching. Transformers: 4.55.4. vLLM: 0.10.1.1.\n",
      "   \\\\   /|    NVIDIA vGPU-32GB. Num GPUs = 1. Max memory: 31.484 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48821bf1a31442c8c9d3e682204f47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.8.9 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# ÂáÜÂ§á‰∏Ä‰∫õÈÖçÁΩÆ\n",
    "max_seq_length = 2048  # ÊúÄÂ§ßÂ∫èÂàóÈïøÂ∫¶\n",
    "dtype = None           # ËÆ©UnslothËá™Âä®Ê£ÄÊµã\n",
    "load_in_4bit = True    # 4bitÈáèÂåñÔºåËäÇÁúÅÊòæÂ≠ò\n",
    "\n",
    "# ËÆ©Êàë‰ª¨ÈÄâÊã©Qwen2.5-Coder-7B-Instruct\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"./trainer_output/checkpoint-4000/\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e01fee79-ea57-4d74-94d8-226a728cc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(response: str):\n",
    "    start_marker = '<|im_start|>assistant\\n'\n",
    "    end_marker = '<|im_end|>'\n",
    "    # Êü•ÊâæÂºÄÂßãÂíåÁªìÊùü‰ΩçÁΩÆ\n",
    "    start_index = response.find(start_marker) + len(start_marker)\n",
    "    end_index = response.find(end_marker, start_index)\n",
    "    \n",
    "    # ÊèêÂèñÂÜÖÂÆπ\n",
    "    content = response[start_index:end_index]\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9463a6c-156e-4db0-914c-59aaadc498c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt):\n",
    "    # ‰ΩøÁî®ÂæÆË∞ÉÊ®°ÂûãËøõË°åÈ¢ÑÊµã\n",
    "    FastLanguageModel.for_inference(model)  # ÂêØÁî®Êé®ÁêÜ‰ºòÂåñ\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs,\n",
    "        max_new_tokens=64,\n",
    "        temperature=1.5,\n",
    "        use_cache=True\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.batch_decode(outputs)\n",
    "    return get_answer(response[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4362395-25a0-43f1-85ef-236a080c4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import csv\n",
    "\n",
    "apikey = \"sk-764f0662965b4ae3ad1cbe6067346100\"\n",
    "client = OpenAI(api_key=apikey,\n",
    "                base_url=\"https://api.deepseek.com\")\n",
    "prompt_template = \"\"\"ËØ∑Ê†πÊçÆ‰ª•‰∏ãÊ†áÂáÜËØÑ‰º∞ÁÖ§ÁüøÂÆâÂÖ®È¢ÜÂüü‰∏ìÂÆ∂ÂØπÁâπÂÆöÂ≠¶ÁßëÈóÆÈ¢òÁöÑ‰ª•‰∏ãÂõûÁ≠î„ÄÇÊÇ®ÂøÖÈ°ªÊåâÁÖß0„ÄÅ1„ÄÅ2Êàñ3È¢óÊòüÁöÑËØÑÂàÜÊ†áÂáÜÂØπÂÖ∂ËøõË°åËØÑÂàÜÔºö\n",
    "\n",
    "ÊÄª‰ΩìËØÑ‰ª∑Ôºö\n",
    "0È¢óÊòüË°®Á§∫ÈîôËØØÁ≠îÊ°àÂíåÈîôËØØËß£Èáä\n",
    "1È¢óÊòüË°®Á§∫ÂõûÁ≠îÈîôËØØÔºå‰ΩÜÈÉ®ÂàÜËß£ÈáäÂêàÁêÜ\n",
    "2È¢óÊòüË°®Á§∫Ê≠£Á°ÆÁ≠îÊ°àÔºåÈÉ®ÂàÜÂêàÁêÜËß£Èáä\n",
    "‰∏âÊòüË°®Á§∫Ê≠£Á°ÆÁ≠îÊ°àÂíåÂêàÁêÜËß£Èáä\n",
    "\n",
    "Áî®Êà∑: {query}\n",
    "\n",
    "LLM: {answer}\n",
    "\n",
    "Áî®Êà∑ÈóÆÈ¢òÁöÑÊ≠£Á°ÆÁ≠îÊ°àÊòØ: {correct_answer}\n",
    "\n",
    "ÊÇ®ÂøÖÈ°ªÊåâÁÖß‰ª•‰∏ãÊ†ºÂºèÊèê‰æõÂèçÈ¶à: \n",
    "{\"ÊÄª‰ΩìËØÑÂàÜ\"ÔºöÊòüÁ∫ßÊï∞ÔºàÊï¥Êï∞Ôºâ}\"\"\"\n",
    "\n",
    "\n",
    "def predict_with_ds(prompt: str):\n",
    "    # ‰ΩøÁî®deepseekËøõË°åËØÑ‰º∞\n",
    "    return client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        top_p=0.7,\n",
    "        temperature=0.1,\n",
    "        stream=False,\n",
    "        max_tokens=2500,\n",
    "    ).choices[0].message.content\n",
    "\n",
    "\n",
    "def eval(query: str, answer: str, correct_answer: str) -> int:\n",
    "    _prompt = prompt_template.replace(\"{query}\", query).replace(\"{answer}\",answer).replace(\"{correct_answer}\",correct_answer)\n",
    "    llm_response_str = predict_with_ds(_prompt)\n",
    "    success = False\n",
    "    retry_time = 0\n",
    "    retry_max_time = 5\n",
    "    eval_score = -1\n",
    "    while not success and retry_time < retry_max_time:\n",
    "        try:\n",
    "            # ËΩ¨Âåñ‰∏∫Â≠óÂÖ∏\n",
    "            eval_score = json.loads(llm_response_str)[\"ÊÄª‰ΩìËØÑÂàÜ\"]\n",
    "            success = True\n",
    "        except:\n",
    "            retry_time += 1\n",
    "            continue\n",
    "    return eval_score\n",
    "\n",
    "def write_to_csv(data: List[Dict[str, Any]], filename: str, mode: str = 'w', encoding: str = 'utf-8-sig'):\n",
    "    \"\"\"\n",
    "    ÂÖ¨ÂÖ±ÁöÑÊñπÊ≥ïÔºåÂ∞ÜÊï∞ÊçÆ‰øùÂ≠ò‰∏∫csvÊñá‰ª∂\n",
    "\n",
    "    :param data: Êï∞ÊçÆ\n",
    "    :param filename: ËæìÂá∫ÁöÑÊñá‰ª∂Âêç\n",
    "    :param mode: Ê®°Âºè\n",
    "    :param encoding: ÁºñÁ†Å\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"Ë≠¶ÂëäÔºöÊï∞ÊçÆ‰∏∫Á©∫ÔºåÊú™ÂÜôÂÖ•Êñá‰ª∂\")\n",
    "        return False\n",
    "    try:\n",
    "        fieldnames = set()\n",
    "        fieldnames.update(data[0].keys())\n",
    "        fieldnames = sorted(list(fieldnames))\n",
    "\n",
    "        # Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶Â≠òÂú®Ôºå‰ª•ÂÜ≥ÂÆöÊòØÂê¶ÈúÄË¶ÅÂÜôÂÖ•Ë°®Â§¥\n",
    "        file_exists = os.path.isfile(filename)\n",
    "        with open(filename, mode, newline='', encoding=encoding) as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            # Â¶ÇÊûúÊòØÊñ∞Êñá‰ª∂ÊàñËÄÖË¶ÜÁõñÊ®°ÂºèÔºåÂÜôÂÖ•Ë°®Â§¥\n",
    "            if mode == 'w' or not file_exists:\n",
    "                writer.writeheader()\n",
    "\n",
    "            # ÂÜôÂÖ•Êï∞ÊçÆ\n",
    "            for item in data:\n",
    "                # Á°Æ‰øùÊØè‰∏™Êï∞ÊçÆÈ°πÈÉΩÂåÖÂê´ÊâÄÊúâÂ≠óÊÆµÔºåÁº∫Â§±Â≠óÊÆµÁî®Á©∫Â≠óÁ¨¶‰∏≤Â°´ÂÖÖ\n",
    "                row = {field: item.get(field, '') for field in fieldnames}\n",
    "                writer.writerow(row)\n",
    "        print(f\"Êï∞ÊçÆÂ∑≤ÊàêÂäüÂÜôÂÖ• {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ÂÜôÂÖ•CSVÊñá‰ª∂Êó∂Âá∫Èîô: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a90002b-ed6a-43b8-9c51-6c462616fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import jieba\n",
    "\n",
    "# Á°Æ‰øùÂ∑≤‰∏ãËΩΩÂàÜËØçÊâÄÈúÄÁöÑÊï∞ÊçÆ\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "\n",
    "def calculate_bleu_scores(candidate, references):\n",
    "    \"\"\"\n",
    "    ËÆ°ÁÆóBLEU 1-4gramÂàÜÊï∞ÂíåÊï¥‰ΩìBLEUÂàÜÊï∞\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "    candidate: Ê®°ÂûãÁîüÊàêÁöÑÊñáÊú¨\n",
    "    references: ÂèÇËÄÉÊñáÊú¨ÂàóË°®\n",
    "\n",
    "    ËøîÂõû:\n",
    "    ÂåÖÂê´ÂêÑÂàÜÊï∞ÂíåÂπ≥ÂùáÂÄºÁöÑÂ≠óÂÖ∏\n",
    "    \"\"\"\n",
    "\n",
    "    # ÊõøÊç¢word_tokenizeÈÉ®ÂàÜ\n",
    "    candidate_tokens = list(jieba.cut(candidate))\n",
    "    reference_tokens = [list(jieba.cut(references))]\n",
    "\n",
    "    # ÂàùÂßãÂåñÂπ≥ÊªëÂáΩÊï∞\n",
    "    smoothie = SmoothingFunction().method4\n",
    "\n",
    "    # ËÆ°ÁÆóÂêÑn-gramÁöÑÂàÜÊï∞\n",
    "    scores = {}\n",
    "    for n in range(1, 5):\n",
    "        weights = [0] * 4\n",
    "        weights[n - 1] = 1\n",
    "        score = sentence_bleu(reference_tokens, candidate_tokens,\n",
    "                              weights=weights,\n",
    "                              smoothing_function=smoothie)\n",
    "        scores[f'BLEU-{n}'] = score\n",
    "\n",
    "    # ËÆ°ÁÆóÊï¥‰ΩìBLEUÂàÜÊï∞Ôºà‰ΩøÁî®Ê†áÂáÜÊùÉÈáçÔºâ\n",
    "    overall_bleu = sentence_bleu(reference_tokens, candidate_tokens,\n",
    "                                 weights=(0.25, 0.25, 0.25, 0.25),\n",
    "                                 smoothing_function=smoothie)\n",
    "    scores['BLEU-Avg'] = overall_bleu\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16b1119a-fdd9-4be9-a89d-7de8c8e8f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "import jieba\n",
    "\n",
    "def cal_rouge_score(predict: str, ground_truth: str) -> dict:\n",
    "    \"\"\"\n",
    "    ËÆ°ÁÆórougeÂÄº\n",
    "\n",
    "    :param predict: Ê®°ÂûãÈ¢ÑÊµã\n",
    "    :param ground_truth: ÁúüÂÆûÁ≠îÊ°à\n",
    "    :return: rouge-1„ÄÅrouge-2„ÄÅrouge-l\n",
    "    \"\"\"\n",
    "    hypothesis_seg = ' '.join(jieba.cut(predict))\n",
    "    reference_seg = ' '.join(jieba.cut(ground_truth))\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(hypothesis_seg, reference_seg)\n",
    "    return {\n",
    "        \"rouge-1_r\": scores[0][\"rouge-1\"][\"r\"],\n",
    "        \"rouge-1_p\": scores[0][\"rouge-1\"][\"p\"],\n",
    "        \"rouge-1_f\": scores[0][\"rouge-1\"][\"f\"],\n",
    "        \"rouge-2_r\": scores[0][\"rouge-2\"][\"r\"],\n",
    "        \"rouge-2_p\": scores[0][\"rouge-2\"][\"p\"],\n",
    "        \"rouge-2_f\": scores[0][\"rouge-2\"][\"f\"],\n",
    "        \"rouge-l_r\": scores[0][\"rouge-l\"][\"r\"],\n",
    "        \"rouge-l_p\": scores[0][\"rouge-l\"][\"p\"],\n",
    "        \"rouge-l_f\": scores[0][\"rouge-l\"][\"f\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b564999-a6f8-40d6-8608-c5511af7afac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.922 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.922 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "DEBUG:jieba:Prefix dict has been built successfully.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [12:38<00:00,  5.06s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "with open(\"./test2.json\", \"r\", encoding=\"utf-8\") as fp: \n",
    "    data_list = json.load(fp)\n",
    "llm_eval_score = 0\n",
    "llm_eval_list = []\n",
    "\n",
    "bleu_score = 0\n",
    "bleu_list = []\n",
    "\n",
    "rouge_f_score = 0\n",
    "rouge_list = []\n",
    "\n",
    "for data in tqdm(data_list):\n",
    "    llm_response = predict(data[\"<input>\"])\n",
    "    \n",
    "    rouge_value = cal_rouge_score(llm_response, data[\"<output>\"])\n",
    "    rouge_value[\"predict\"] = llm_response\n",
    "    rouge_value[\"ground_truth\"] = data[\"<output>\"]\n",
    "    rouge_f_score += ((rouge_value[\"rouge-1_f\"] + rouge_value[\"rouge-2_f\"] + rouge_value[\"rouge-l_f\"])/3)\n",
    "    rouge_list.append(rouge_value)\n",
    "    \n",
    "    bleu_value = calculate_bleu_scores(llm_response, data[\"<output>\"])\n",
    "    bleu_value[\"predict\"] = llm_response\n",
    "    bleu_value[\"ground_truth\"] = data[\"<output>\"]\n",
    "    bleu_list.append(bleu_value)\n",
    "    bleu_score += bleu_value[\"BLEU-Avg\"]\n",
    "\n",
    "    \n",
    "    llm_eval_value = eval(data[\"<input>\"], llm_response,data[\"<output>\"])\n",
    "    llm_eval_list.append({\"predict\": llm_response, \"ground_truth\": data[\"<output>\"], \"llm_eval\": llm_eval_value})\n",
    "    llm_eval_score += llm_eval_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8859bb96-ecc2-484a-b55f-3ac9b132b818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Êï∞ÊçÆÂ∑≤ÊàêÂäüÂÜôÂÖ• ./eval_result/lora/rouge.csv\n",
      "Êï∞ÊçÆÂ∑≤ÊàêÂäüÂÜôÂÖ• ./eval_result/lora/bleu.csv\n",
      "Êï∞ÊçÆÂ∑≤ÊàêÂäüÂÜôÂÖ• ./eval_result/lora/llm_eval.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_to_csv(rouge_list, \"./eval_result/lora/rouge.csv\")\n",
    "write_to_csv(bleu_list, \"./eval_result/lora/bleu.csv\")\n",
    "write_to_csv(llm_eval_list, \"./eval_result/lora/llm_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6532f2bf-6b65-4c1b-96ef-d3e784011e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-Eval: 0.62\n",
      "bleu_avg:  0.36603007624269324\n",
      "rouge: 0.5683751738565632\n"
     ]
    }
   ],
   "source": [
    "print(\"LLM-Eval:\", llm_eval_score/(len(data_list)*3))\n",
    "print(\"bleu_avg: \", bleu_score/len(data_list))\n",
    "print(\"rouge:\" , rouge_f_score/len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a9d44-f2ca-4b37-a350-343b1166c1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
